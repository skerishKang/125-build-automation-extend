"""Voice and photo handlers extracted from the runtime module."""

from __future__ import annotations

import asyncio
import os
import tempfile
from typing import TYPE_CHECKING, Any, List, Optional

if TYPE_CHECKING:  # pragma: no cover - type hints only
    from telegram import Update
    from telegram.ext import ContextTypes


async def handle_photo(runtime: Any, update: "Update", context: "ContextTypes.DEFAULT_TYPE") -> None:
    """Handle incoming photos with Gemini multimodal analysis."""
    GEMINI_API_KEY = runtime.GEMINI_API_KEY
    gemini_model = runtime.gemini_model
    ActionIndicator = runtime.ActionIndicator
    ChatAction = runtime.ChatAction
    format_plain = runtime.format_plain
    reply_text = runtime.reply_text
    logger = runtime.logger

    if not GEMINI_API_KEY or not gemini_model:
        await reply_text(update, "Gemini ì„¤ì •ì´ ì—†ì–´ ì´ë¯¸ì§€ ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ìš”.")
        return

    progress_messages: List = []
    progress_messages.append(await update.message.reply_text("ğŸ“· ì´ë¯¸ì§€ë¥¼ ë°›ì•˜ì–´ìš”. ë¶„ì„ ì¤‘â€¦ [0%]"))

    tmp: Optional[str] = None
    photo_indicator: Optional[ActionIndicator] = None

    try:
        photo = update.message.photo[-1]
        file = await context.bot.get_file(photo.file_id)
        tmp = os.path.join(tempfile.gettempdir(), f"{photo.file_id}.jpg")
        photo_indicator = ActionIndicator(context, update.effective_chat.id, ChatAction.UPLOAD_PHOTO)
        await photo_indicator.__aenter__()
        await file.download_to_drive(tmp)

        progress_messages.append(await update.message.reply_text("ğŸ“· ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ. ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘â€¦ [50%]"))

        import google.generativeai as genai  # noqa: WPS433

        with open(tmp, "rb") as image_fp:
            image_part = {"mime_type": "image/jpeg", "data": image_fp.read()}

        prompt = (
            "ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ìº¡ì…˜ì„ ì‘ì„±í•´ì¤˜. ì´ë¯¸ì§€ì˜ ì£¼ìš” ë‚´ìš©, ìƒ‰ê°/ë¶„ìœ„ê¸°, ë§¥ë½ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n"
            "í•­ìƒ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³ , Markdown í‘œ/ì½”ë“œë¸”ë¡ ì—†ì´ ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”."
        )

        response = gemini_model.generate_content([prompt, image_part])
        answer = format_plain(response.text.strip())

        progress_messages.append(await update.message.reply_text("âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ! [100%]"))

        final_text = f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì„¤ëª…:\n{answer}"
        await reply_text(update, final_text)
    except Exception as exc:  # pragma: no cover - defensive logging
        logger.error("photo error: %s", exc)
        await reply_text(update, "ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆì–´ìš”.")
    finally:
        if tmp and os.path.exists(tmp):
            try:
                os.remove(tmp)
            except Exception:  # pragma: no cover - cleanup best effort
                pass
        if photo_indicator:
            try:
                await photo_indicator.__aexit__(None, None, None)
            except Exception:  # pragma: no cover - cleanup best effort
                pass


async def handle_voice(runtime: Any, update: "Update", context: "ContextTypes.DEFAULT_TYPE") -> None:
    """Handle incoming voice messages with adaptive processing."""
    GEMINI_API_KEY = runtime.GEMINI_API_KEY
    gemini_model = runtime.gemini_model
    reply_text = runtime.reply_text

    if not GEMINI_API_KEY or not gemini_model:
        await reply_text(update, "Gemini ì„¤ì •ì´ ì—†ì–´ ìŒì„± ì²˜ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ìš”.")
        return

    ack_msg = None
    try:
        ack_msg = await update.message.reply_text(
            "ğŸ¤ ìŒì„±ì„ ë°›ì•˜ì–´ìš”. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤! "
            "ë‹¤ë¥¸ ë©”ì‹œì§€ë„ ë°”ë¡œ ë³´ë‚¼ ìˆ˜ ìˆì–´ìš”. ğŸ˜Š"
        )
    except Exception:  # pragma: no cover - best effort ack
        ack_msg = None

    chat_id = update.effective_chat.id
    user_id = str(update.effective_user.id)
    username = update.effective_user.first_name or "ì‚¬ìš©ì"

    asyncio.create_task(
        process_voice_background(runtime, update, context, chat_id, user_id, username, ack_msg)
    )


async def process_voice_background(
    runtime: Any,
    update,
    context,
    chat_id: int,
    user_id: str,
    username: str,
    ack_msg,
) -> None:
    """Process voice in background - non-blocking, allows immediate responses."""
    logger = runtime.logger
    get_audio_duration = runtime.get_audio_duration
    SHORT_AUDIO_THRESHOLD = runtime.SHORT_AUDIO_THRESHOLD
    LONG_AUDIO_THRESHOLD = runtime.LONG_AUDIO_THRESHOLD
    MID_LENGTH_MODEL = runtime.MID_LENGTH_MODEL
    save_memory = runtime.save_memory

    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    ogg_path = os.path.join(tempfile.gettempdir(), f"{voice.file_id}.ogg")
    wav_path = os.path.join(tempfile.gettempdir(), f"{voice.file_id}.wav")

    progress_messages: List = []

    try:
        await file.download_to_drive(ogg_path)
        progress_messages.append(await context.bot.send_message(chat_id, "ğŸ“¥ ìŒì„± íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ. [20%]"))

        duration = get_audio_duration(ogg_path)
        progress_messages.append(
            await context.bot.send_message(
                chat_id,
                f"â±ï¸ ìŒì„± ê¸¸ì´ ë¶„ì„: {duration:.1f}ì´ˆ. ì²˜ë¦¬ ë°©ì‹ ê²°ì • ì¤‘... [40%]",
            )
        )

        if duration <= SHORT_AUDIO_THRESHOLD:
            result = await process_with_gemini_multimodal(runtime, ogg_path, duration, chat_id, context, progress_messages)
            mode = "Gemini 2.5 Flash (ë©€í‹°ëª¨ë‹¬)"
        elif duration >= LONG_AUDIO_THRESHOLD:
            result = await process_with_whisper_gemini(runtime, ogg_path, wav_path, duration, chat_id, context, progress_messages)
            mode = "Whisper + Gemini (ì •í™•ë„ ìµœì í™”)"
        else:
            if MID_LENGTH_MODEL == "gemini":
                result = await process_with_gemini_multimodal(runtime, ogg_path, duration, chat_id, context, progress_messages)
                mode = "Gemini 2.5 Flash (ë©€í‹°ëª¨ë‹¬)"
            else:
                result = await process_with_whisper_gemini(runtime, ogg_path, wav_path, duration, chat_id, context, progress_messages)
                mode = "Whisper + Gemini (ì •í™•ë„ ìµœì í™”)"

        progress_messages.append(await context.bot.send_message(chat_id, "âœ… ìŒì„± ì²˜ë¦¬ ì™„ë£Œ! [100%]"))

        if result:
            final_text = f"ğŸ¤ {mode} ì²˜ë¦¬ ê²°ê³¼ ({duration:.1f}ì´ˆ):\n\n{result}"
            await context.bot.send_message(chat_id, final_text)
            await save_memory(user_id, username, f"[ìŒì„±] {duration:.1f}ì´ˆ", result)

    except Exception as exc:  # pragma: no cover - defensive logging
        logger.error("Voice processing error: %s", exc)
        error_msg = f"ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {str(exc)[:100]}"
        await context.bot.send_message(chat_id, error_msg)
    finally:
        for path in (ogg_path, wav_path):
            try:
                if os.path.exists(path):
                    os.remove(path)
            except Exception:  # pragma: no cover - cleanup best effort
                pass


async def process_with_gemini_multimodal(
    runtime: Any,
    ogg_path: str,
    duration: float,
    chat_id: int,
    context,
    progress_messages,
) -> str:
    """Process short audio with Gemini 2.5 Flash multimodal."""
    gemini_model = runtime.gemini_model
    format_plain = runtime.format_plain

    progress_messages.append(
        await context.bot.send_message(
            chat_id,
            f"ğŸ¤ {duration:.1f}ì´ˆ (ì§§ìŒ) - Gemini 2.5 Flash ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘... [60%]",
        )
    )

    import google.generativeai as genai  # noqa: WPS433

    with open(ogg_path, "rb") as audio_fp:
        audio_part = {"mime_type": "audio/ogg", "data": audio_fp.read()}

    prompt = (
        "ì´ ìŒì„± ë©”ì‹œì§€ë¥¼ í•œêµ­ì–´ë¡œ ì „ì‚¬í•˜ê³  ì ì ˆíˆ ìš”ì•½/ë‹µë³€í•´ì£¼ì„¸ìš”.\n"
        "ìŒì„± ë‚´ìš©ì— ì§ì ‘ ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ë©´ ë‹µë³€ë„ ì œê³µí•´ì£¼ì„¸ìš”.\n"
        "í•­ìƒ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³ , Markdown í‘œ/ì½”ë“œë¸”ë¡ ì—†ì´ ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”."
    )

    def _call_gemini():
        response = gemini_model.generate_content([prompt, audio_part])
        return response.text.strip()

    result = await asyncio.to_thread(_call_gemini)
    return format_plain(result)


async def process_with_whisper_gemini(
    runtime: Any,
    ogg_path: str,
    wav_path: str,
    duration: float,
    chat_id: int,
    context,
    progress_messages,
) -> str:
    """Process long audio with Whisper + Gemini."""
    gemini_model = runtime.gemini_model
    format_plain = runtime.format_plain

    progress_messages.append(
        await context.bot.send_message(
            chat_id,
            f"ğŸ¤ {duration:.1f}ì´ˆ (ê¹€ìŒ) - Whisperë¡œ ì „ì‚¬ ì¤‘... [60%]",
        )
    )

    try:
        proc = await asyncio.create_subprocess_exec(
            "ffmpeg",
            "-y",
            "-i",
            ogg_path,
            "-ar",
            "16000",
            "-ac",
            "1",
            wav_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        _stdout, _stderr = await proc.communicate()
        if proc.returncode != 0:
            raise RuntimeError("ffmpeg ë³€í™˜ ì‹¤íŒ¨")
    except Exception as exc:
        raise Exception(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {str(exc)}")

    progress_messages.append(await context.bot.send_message(chat_id, "ğŸ¤ ì „ì‚¬ ì™„ë£Œ! Geminië¡œ ìš”ì•½ ì¤‘... [80%]"))

    try:
        from faster_whisper import WhisperModel  # noqa: WPS433

        if not hasattr(process_with_whisper_gemini, "_whisper"):
            process_with_whisper_gemini._whisper = WhisperModel("base", device="cpu", compute_type="int8")
        whisper_model = process_with_whisper_gemini._whisper

        def _transcribe():
            segments, _info = whisper_model.transcribe(wav_path, language="ko", vad_filter=True)
            return " ".join([segment.text.strip() for segment in segments if segment.text]).strip()

        transcription = await asyncio.to_thread(_transcribe)

        if not transcription:
            return "ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”."

        def _summarize():
            prompt = (
                f"ë‹¤ìŒ ìŒì„± ë©”ì‹œì§€ê°€ ì „ì‚¬ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì ì ˆíˆ ìš”ì•½í•˜ê±°ë‚˜ ë‹µë³€í•´ ì£¼ì„¸ìš”:\n\n{transcription}\n\n"
                "í•­ìƒ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³ , Markdown í‘œ/ì½”ë“œë¸”ë¡ ì—†ì´ ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”."
            )
            response = gemini_model.generate_content(prompt)
            return response.text.strip()

        result = await asyncio.to_thread(_summarize)
        return format_plain(result)

    except ImportError:
        return "faster-whisperê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ìš”. ë°±ì—”ë“œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
