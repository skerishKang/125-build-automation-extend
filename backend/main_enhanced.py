"""
125 Build Automation Enhanced - AI ë¬¸ì„œ ë¶„ì„ ë´‡ (í™•ì¥ ë²„ì „)
Gemini ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ + RAG + í…”ë ˆê·¸ë¨/ë“œë¼ì´ë¸Œ í†µí•©
"""
import os
import asyncio
import logging
from datetime import datetime
from typing import Optional, Dict, List, Any

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import google.generativeai as genai
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import telegram
from telegram import Update, File
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
import httpx
import chardet
import markdown_it
from bs4 import BeautifulSoup
import csv
import openpyxl
from pptx import Presentation
import json
import hashlib
from pathlib import Path

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
ENABLE_RAG = os.getenv('ENABLE_RAG', 'false').lower() == 'true'
VECTOR_STORE_PATH = os.getenv('VECTOR_STORE_PATH', 'data/store')
GEN_TEMPERATURE = float(os.getenv('GEN_TEMPERATURE', '0.2'))
GEN_MAX_OUTPUT_TOKENS = int(os.getenv('GEN_MAX_OUTPUT_TOKENS', '2048'))

# ì¡°ê±´ë¶€ import (RAG í™œì„±í™” ì‹œì—ë§Œ)
faiss = None
chromadb = None
SentenceTransformer = None

if ENABLE_RAG:
    try:
        import faiss
        import chromadb
        from sentence_transformers import SentenceTransformer
    except ImportError as e:
        logger.warning(f"RAG ê´€ë ¨ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
        ENABLE_RAG = False

# Gemini ëª¨ë¸ ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
model = None
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    generation_config = genai.GenerationConfig(
        temperature=GEN_TEMPERATURE,
        top_p=0.9,
        max_output_tokens=GEN_MAX_OUTPUT_TOKENS
    )
    model = genai.GenerativeModel('gemini-2.5-flash', generation_config=generation_config)

# ê¸€ë¡œë²Œ ë³€ìˆ˜
drive_service = None
telegram_app = None
vector_store = None
embedding_model = None

async def init_services():
    """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    global drive_service, telegram_app, vector_store, embedding_model

    # Gemini í™•ì¸
    if not GEMINI_API_KEY:
        logger.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return False

    # RAG ì´ˆê¸°í™” (ì„ íƒ)
    if ENABLE_RAG:
        try:
            embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            Path(VECTOR_STORE_PATH).mkdir(parents=True, exist_ok=True)
            vector_store = chromadb.PersistentClient(path=VECTOR_STORE_PATH)
            logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    logger.info("ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    return True

# ===== ë²”ìš© ë¬¸ì„œ ì¶”ì¶œê¸° =====

def extract_text_from_markdown(path: str) -> str:
    """Markdown íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()

        # markdown-itìœ¼ë¡œ HTML ë³€í™˜ í›„ BeautifulSoupìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        md = markdown_it.MarkdownIt()
        html = md.render(content)
        soup = BeautifulSoup(html, 'html.parser')

        # í—¤ë”©, ëª©ë¡ ë“± êµ¬ì¡° ìœ ì§€í•˜ë©´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        return soup.get_text(separator='\n', strip=True)
    except Exception as e:
        logger.warning(f"Markdown ì¶”ì¶œ ì‹¤íŒ¨, UTF-8 ì¬ì‹œë„: {e}")
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except Exception as e2:
            logger.error(f"Markdown ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨: {e2}")
            return ""

def extract_text_from_html(path: str) -> str:
    """HTML íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()

        soup = BeautifulSoup(content, 'html.parser')

        # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ ì œê±°
        for script in soup(["script", "style"]):
            script.decompose()

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        return soup.get_text(separator='\n', strip=True)
    except Exception as e:
        logger.error(f"HTML ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_text_from_csv(path: str) -> str:
    """CSV íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            rows = list(reader)

        # í—¤ë”ì™€ ë°ì´í„° ê²°í•©
        text_parts = []
        if rows:
            text_parts.append("CSV Headers: " + ", ".join(rows[0]))
            for i, row in enumerate(rows[1:], 1):
                text_parts.append(f"Row {i}: " + ", ".join(row))

        return "\n".join(text_parts)
    except Exception as e:
        logger.error(f"CSV ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_text_from_xlsx(path: str) -> str:
    """Excel íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        wb = openpyxl.load_workbook(path, read_only=True)
        text_parts = []

        for sheet_name in wb.sheetnames:
            sheet = wb[sheet_name]
            text_parts.append(f"Sheet: {sheet_name}")

            for row in sheet.iter_rows(values_only=True):
                # Noneì´ ì•„ë‹Œ ê°’ë§Œ í•„í„°ë§
                row_data = [str(cell) for cell in row if cell is not None]
                if row_data:
                    text_parts.append(", ".join(row_data))

        return "\n".join(text_parts)
    except Exception as e:
        logger.error(f"XLSX ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_text_from_pptx(path: str) -> str:
    """PowerPoint íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        prs = Presentation(path)
        text_parts = []

        for i, slide in enumerate(prs.slides, 1):
            text_parts.append(f"Slide {i}:")
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text:
                    text_parts.append(shape.text)

        return "\n".join(text_parts)
    except Exception as e:
        logger.error(f"PPTX ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_text_from_pdf(path: str) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        import PyPDF2
        with open(path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        # pdfplumberë¡œ ì¬ì‹œë„
        try:
            import pdfplumber
            with pdfplumber.open(path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() + "\n"
            return text.strip()
        except Exception as e2:
            logger.error(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {e2}")
            return ""

def extract_text_fallback(path: str) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ (chardetë¡œ ì¸ì½”ë”© ì¶”ì •)"""
    try:
        with open(path, 'rb') as f:
            raw_data = f.read()

        # ì¸ì½”ë”© ì¶”ì •
        detected = chardet.detect(raw_data)
        encoding = detected.get('encoding', 'utf-8')

        # ì¶”ì •ëœ ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”©
        return raw_data.decode(encoding, errors='ignore')
    except Exception as e:
        logger.error(f"Fallback ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def get_text_extractor(mime_type: str, file_path: str) -> str:
    """MIME íƒ€ì…ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ì„ íƒ"""
    mime_to_extractor = {
        'text/markdown': extract_text_from_markdown,
        'text/html': extract_text_from_html,
        'text/csv': extract_text_from_csv,
        'application/pdf': extract_text_from_pdf,
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': extract_text_from_xlsx,
        'application/vnd.openxmlformats-officedocument.presentationml.presentation': extract_text_from_pptx,
    }

    # í™•ì¥ì ê¸°ë°˜ ì¶”ê°€ ë§¤í•‘
    ext_to_extractor = {
        '.md': extract_text_from_markdown,
        '.markdown': extract_text_from_markdown,
        '.html': extract_text_from_html,
        '.htm': extract_text_from_html,
        '.csv': extract_text_from_csv,
        '.pdf': extract_text_from_pdf,
        '.xlsx': extract_text_from_xlsx,
        '.pptx': extract_text_from_pptx,
    }

    # MIME íƒ€ì… ìš°ì„ 
    if mime_type in mime_to_extractor:
        return mime_to_extractor[mime_type](file_path)

    # í™•ì¥ì ê¸°ë°˜
    ext = Path(file_path).suffix.lower()
    if ext in ext_to_extractor:
        return ext_to_extractor[ext](file_path)

    # ê¸°íƒ€ í…ìŠ¤íŠ¸ íŒŒì¼
    if mime_type.startswith('text/') or ext in ['.txt', '.log', '.json', '.xml']:
        return extract_text_fallback(file_path)

    return ""

# ===== ì²­í¬ + ë§µë¦¬ë“€ìŠ¤ ìš”ì•½ ìœ í‹¸ë¦¬í‹° =====

def split_into_chunks(text: str, chunk_chars: int = 4000, overlap: int = 400) -> List[str]:
    """í…ìŠ¤íŠ¸ë¥¼ ê²¹ì¹˜ëŠ” ì²­í¬ë¡œ ë¶„í• """
    if len(text) <= chunk_chars:
        return [text]

    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_chars

        # ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
        if end < len(text):
            # ê³µë°±ì´ë‚˜ ì¤„ë°”ê¿ˆì—ì„œ ìë¥´ê¸°
            while end > start and text[end] not in [' ', '\n', '\t']:
                end -= 1
            if end == start:  # ë‹¨ì–´ ê²½ê³„ ëª» ì°¾ìŒ
                end = start + chunk_chars

        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)

        start = end - overlap
        if start >= len(text):
            break

    return chunks

def summarize_chunk(chunk: str) -> str:
    """ë‹¨ì¼ ì²­í¬ ìš”ì•½"""
    prompt = f"""ì—­í• : ì „ë¬¸ê°€ ë³´ì¡° ì—ì´ì „íŠ¸

ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”ì•½ ì§€ì¹¨:
- ì„¹ì…˜ë³„ë¡œ êµ¬ì¡°í™”: ìš”ì•½/í•µì‹¬í¬ì¸íŠ¸/ì•¡ì…˜ì•„ì´í…œ/ë‚ ì§œ/ë¦¬ìŠ¤í¬
- ê·¼ê±°ê°€ ì•½í•˜ë©´ 'ì¶”ì •'ìœ¼ë¡œ í‘œê¸°
- ê°„ê²°í•˜ê³  êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì‘ì„±

í…ìŠ¤íŠ¸:
{chunk}

ìš”ì•½:"""

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"ì²­í¬ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return f"ìš”ì•½ ì‹¤íŒ¨: {chunk[:200]}..."

def compose_summaries(summaries: List[str]) -> str:
    """ì²­í¬ ìš”ì•½ë“¤ì„ í†µí•© ìš”ì•½"""
    combined = "\n\n".join(f"ì²­í¬ {i+1}: {summary}" for i, summary in enumerate(summaries))

    prompt = f"""ì—­í• : ì „ë¬¸ê°€ ë³´ì¡° ì—ì´ì „íŠ¸

ë‹¤ìŒì€ ì—¬ëŸ¬ ì²­í¬ì˜ ìš”ì•½ì…ë‹ˆë‹¤. ì´ë¥¼ ì¢…í•©í•˜ì—¬ ì „ì²´ ë¬¸ì„œì˜ í†µí•© ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í†µí•© ìš”ì•½ ì§€ì¹¨:
- ì „ì²´ ë¬¸ì„œì˜ ì£¼ìš” í…Œë§ˆì™€ ë‚´ìš©ì„ í¬ê´„
- ì„¹ì…˜ë³„ êµ¬ì¡°í™” ìœ ì§€
- ì¤‘ë³µ ì œê±° ë° ì¼ê´€ì„± í™•ë³´
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ê°•ì¡°

ì²­í¬ ìš”ì•½ë“¤:
{combined}

í†µí•© ìš”ì•½:"""

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"í†µí•© ìš”ì•½ ì‹¤íŒ¨: {e}")
        return "í†µí•© ìš”ì•½ ì‹¤íŒ¨: " + " ".join(summaries)

def summarize_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ìš”ì•½ (í•„ìš”ì‹œ)"""
    if len(text) <= 4000:
        # ë‹¨ì¼ íŒ¨ìŠ¤ ìš”ì•½
        return summarize_chunk(text)

    # ì²­í¬ + ë§µë¦¬ë“€ìŠ¤
    chunks = split_into_chunks(text)
    summaries = [summarize_chunk(chunk) for chunk in chunks]
    return compose_summaries(summaries)

# ===== Google Drive í†µí•© =====

async def init_drive_service():
    """Google Drive API ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    global drive_service

    try:
        creds = None
        token_path = 'token.json'

        if os.path.exists(token_path):
            creds = Credentials.from_authorized_user_file(token_path, SCOPES)

        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(
                    'credentials.json', SCOPES)
                creds = flow.run_local_server(port=0)

            with open(token_path, 'w') as token:
                token.write(creds.to_json())

        drive_service = build('drive', 'v3', credentials=creds)
        logger.info("Google Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        return True

    except Exception as e:
        logger.error(f"Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def analyze_drive_file(file_id: str, mime_type: str, file_name: str) -> Dict[str, Any]:
    """Drive íŒŒì¼ ë¶„ì„ ë° ìš”ì•½"""
    try:
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        request = drive_service.files().get_media(fileId=file_id)
        file_path = f"/tmp/{file_id}_{file_name}"

        with open(file_path, 'wb') as f:
            f.write(request.execute())

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = get_text_extractor(mime_type, file_path)

        if not text:
            return {
                'success': False,
                'error': 'í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨',
                'file_name': file_name
            }

        # ìš”ì•½
        summary = summarize_text(text)

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.remove(file_path)

        return {
            'success': True,
            'file_name': file_name,
            'summary': summary,
            'text_length': len(text)
        }

    except Exception as e:
        logger.error(f"Drive íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'success': False,
            'error': str(e),
            'file_name': file_name
        }

# ===== Telegram ë´‡ í•¸ë“¤ëŸ¬ =====

# ê¸€ë¡œë²Œ ë³€ìˆ˜ì— ìµœê·¼ ë¬¸ì„œ ì €ì¥
recent_documents = {}

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """í…”ë ˆê·¸ë¨ ë¬¸ì„œ í•¸ë“¤ëŸ¬ - ë¬¸ì„œ ì €ì¥ë§Œ ìˆ˜í–‰"""
    try:
        document = update.message.document
        if not document:
            return

        file_name = document.file_name
        mime_type = document.mime_type
        file_id = document.file_id
        user_id = update.effective_user.id

        # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ ì²´í¬
        supported_extensions = ['.md', '.markdown', '.html', '.csv', '.pdf', '.xlsx', '.pptx', '.txt', '.log', '.json']
        file_ext = Path(file_name).suffix.lower()

        if file_ext not in supported_extensions and not mime_type.startswith('text/'):
            await update.message.reply_text(
                f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_ext}\n"
                "ì§€ì› í˜•ì‹: .md, .html, .csv, .pdf, .xlsx, .pptx, .txt, .log, .json"
            )
            return

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì„ì‹œ ì €ì¥
        file = await context.bot.get_file(file_id)
        file_path = f"/tmp/{file_id}_{file_name}"

        await file.download_to_drive(file_path)

        # ì‚¬ìš©ìë³„ ìµœê·¼ ë¬¸ì„œ ì €ì¥
        if user_id not in recent_documents:
            recent_documents[user_id] = []

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = get_text_extractor(mime_type, file_path)

        if not text:
            await update.message.reply_text("âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (íŒŒì¼ í˜•ì‹ì´ ì§€ì›ë˜ì§€ ì•Šê±°ë‚˜ ì†ìƒë¨)")
            os.remove(file_path)
            return

        doc_info = {
            'file_name': file_name,
            'file_path': file_path,
            'mime_type': mime_type,
            'text': text,
            'text_length': len(text),
            'timestamp': datetime.now()
        }

        recent_documents[user_id].append(doc_info)

        # RAG ì €ì¥ (í™œì„±í™”ëœ ê²½ìš°)
        if ENABLE_RAG:
            await rag_store_document(file_path, file_name, text, str(user_id))

        # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì €ì¥
        if len(recent_documents[user_id]) > 5:
            old_doc = recent_documents[user_id].pop(0)
            if os.path.exists(old_doc['file_path']):
                os.remove(old_doc['file_path'])

        await update.message.reply_text(
            f"- **ë¬¸ì„œ ì €ì¥ ì™„ë£Œ**\n\n"
            f"- **íŒŒì¼ëª…:** {file_name}\n"
            f"- **í˜•ì‹:** {mime_type}\n\n"
            f"- ë¶„ì„ì„ ì›í•˜ì‹œë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”:\n"
            f"- `/analyze` - ìµœê·¼ ë¬¸ì„œ ë¶„ì„\n"
            f"- `/summarize` - ìµœê·¼ ë¬¸ì„œ ìš”ì•½\n"
            f"- `/ask [ì§ˆë¬¸]` - ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸",
            parse_mode='Markdown'
        )

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
        await update.message.reply_text("âŒ ë¬¸ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def handle_analyze(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ë¬¸ì„œ ë¶„ì„ í•¸ë“¤ëŸ¬ (/analyze ëª…ë ¹)"""
    user_id = update.effective_user.id

    if user_id not in recent_documents or not recent_documents[user_id]:
        await update.message.reply_text("âŒ ìµœê·¼ì— ì—…ë¡œë“œí•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    try:
        # ê°€ì¥ ìµœê·¼ ë¬¸ì„œ ë¶„ì„
        latest_doc = recent_documents[user_id][-1]

        await update.message.reply_text("ğŸ” ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

        # AI ë¶„ì„ ìˆ˜í–‰
        analysis_prompt = f"""ì—­í• : ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ê°€

ë‹¤ìŒ ë¬¸ì„œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
- ë¬¸ì„œì˜ ì£¼ìš” ëª©ì ê³¼ ë‚´ìš© íŒŒì•…
- êµ¬ì¡°ì™€ êµ¬ì„± ìš”ì†Œ ë¶„ì„
- í•µì‹¬ ê°œë…ê³¼ ì£¼ìš” í¬ì¸íŠ¸ ë„ì¶œ
- ì ì¬ì  í™œìš© ë°©ì•ˆ ì œì‹œ
- ê°œì„ ì ì´ë‚˜ ì£¼ì˜ì‚¬í•­ ì–¸ê¸‰

ë¬¸ì„œ ì •ë³´:
- íŒŒì¼ëª…: {latest_doc['file_name']}
- í˜•ì‹: {latest_doc['mime_type']}
- ê¸¸ì´: {latest_doc['text_length']}ì

ë¬¸ì„œ ë‚´ìš©:
{latest_doc['text']}

ë¶„ì„ ê²°ê³¼:"""

        response = model.generate_content(analysis_prompt)
        analysis = response.text.strip()

        response_msg = f"ğŸ“Š **ë¬¸ì„œ ë¶„ì„ ê²°ê³¼**\n\n**íŒŒì¼:** {latest_doc['file_name']}\n\n{analysis}"

        if len(response_msg) > 4000:
            response_msg = response_msg[:3997] + "..."

        await update.message.reply_text(response_msg, parse_mode='Markdown')

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        await update.message.reply_text("âŒ ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def handle_summarize(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ë¬¸ì„œ ìš”ì•½ í•¸ë“¤ëŸ¬ (/summarize ëª…ë ¹)"""
    user_id = update.effective_user.id

    if user_id not in recent_documents or not recent_documents[user_id]:
        await update.message.reply_text("âŒ ìµœê·¼ì— ì—…ë¡œë“œí•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    try:
        # ê°€ì¥ ìµœê·¼ ë¬¸ì„œ ìš”ì•½
        latest_doc = recent_documents[user_id][-1]

        await update.message.reply_text("ğŸ“ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

        # ìš”ì•½ ìˆ˜í–‰
        summary = summarize_text(latest_doc['text'])

        response_msg = f"ğŸ“„ **ë¬¸ì„œ ìš”ì•½ ê²°ê³¼**\n\n**íŒŒì¼:** {latest_doc['file_name']}\n**í…ìŠ¤íŠ¸ ê¸¸ì´:** {latest_doc['text_length']}ì\n\n{summary}"

        if len(response_msg) > 4000:
            response_msg = response_msg[:3997] + "..."

        await update.message.reply_text(response_msg, parse_mode='Markdown')

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ìš”ì•½ ì‹¤íŒ¨: {e}")
        await update.message.reply_text("âŒ ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def handle_list(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ í•¸ë“¤ëŸ¬ (/list ëª…ë ¹)"""
    user_id = update.effective_user.id

    if user_id not in recent_documents or not recent_documents[user_id]:
        await update.message.reply_text("ğŸ“‚ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        doc_list = []
        for i, doc in enumerate(recent_documents[user_id], 1):
            timestamp = doc['timestamp'].strftime('%H:%M:%S')
            doc_list.append(f"{i}. {doc['file_name']} ({doc['text_length']}ì) - {timestamp}")

        response = "ğŸ“‚ **ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡**\n\n" + "\n".join(doc_list)
        response += f"\n\nì´ {len(recent_documents[user_id])}ê°œ ë¬¸ì„œê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

        await update.message.reply_text(response, parse_mode='Markdown')

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        await update.message.reply_text("âŒ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬"""
    user_id = update.effective_user.id
    message_text = update.message.text.strip()

    # ëª…ë ¹ì–´ ì¸ì‹
    if message_text.startswith('/'):
        return  # ëª…ë ¹ì–´ëŠ” ë³„ë„ í•¸ë“¤ëŸ¬ì—ì„œ ì²˜ë¦¬

    # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
    if user_id in recent_documents and recent_documents[user_id]:
        try:
            # RAGê°€ í™œì„±í™”ëœ ê²½ìš°
            if ENABLE_RAG and vector_store:
                answer = await rag_query(message_text, str(user_id))
                response = f"ğŸ¤– **ì§ˆë¬¸:** {message_text}\n\n**ë‹µë³€:**\n{answer}"
            else:
                # ìµœê·¼ ë¬¸ì„œì— ëŒ€í•´ ì¼ë°˜ AI ì§ˆë¬¸
                latest_doc = recent_documents[user_id][-1]

                prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìµœê·¼ ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ì •ë³´:
- íŒŒì¼ëª…: {latest_doc['file_name']}
- ë‚´ìš©: {latest_doc['text'][:2000]}... (ì¶•ì•½)

ì§ˆë¬¸: {message_text}

ë‹µë³€:"""

                response = model.generate_content(prompt)
                answer = response.text.strip()
                response = f"ğŸ¤– **ì§ˆë¬¸:** {message_text}\n\n**ë‹µë³€:**\n{answer}"

            if len(response) > 4000:
                response = response[:3997] + "..."

            await update.message.reply_text(response, parse_mode='Markdown')

        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            await update.message.reply_text("âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
    else:
        # ê¸°ë³¸ ë„ì›€ë§
        help_msg = """ğŸ¤– **125 Build Automation ë´‡**

ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:
- ë¬¸ì„œ ì—…ë¡œë“œ í›„ ë‹¤ìŒ ëª…ë ¹ì–´ ì‚¬ìš©:
  - `/analyze` - ë¬¸ì„œ ì „ë¬¸ ë¶„ì„
  - `/summarize` - ë¬¸ì„œ ìš”ì•½
  - `/list` - ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡
  - `/ask [ì§ˆë¬¸]` - RAG ê¸°ë°˜ ì§ˆë¬¸

- ë˜ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ê¸°

ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!"""
        await update.message.reply_text(help_msg, parse_mode='Markdown')

async def handle_ask(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ì§ˆë¬¸ í•¸ë“¤ëŸ¬ (/ask ëª…ë ¹)"""
    if not ENABLE_RAG or not vector_store:
        await update.message.reply_text("âŒ RAG ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return

    try:
        query = " ".join(context.args)
        if not query:
            await update.message.reply_text("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: /ask [ì§ˆë¬¸]")
            return

        user_id = update.effective_user.id
        # RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
        answer = await rag_query(query, str(user_id))

        await update.message.reply_text(f"ğŸ¤– **ì§ˆë¬¸:** {query}\n\n**ë‹µë³€:**\n{answer}", parse_mode='Markdown')

    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        await update.message.reply_text("âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

# ===== RAG ì‹œìŠ¤í…œ =====

async def rag_store_document(file_path: str, file_name: str, text: str, owner_id: str):
    """ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥"""
    if not ENABLE_RAG or not vector_store or not embedding_model:
        return False

    try:
        collection_name = f"docs_{owner_id}"
        collection = vector_store.get_or_create_collection(name=collection_name)

        # ì²­í¬ ë¶„í• 
        chunks = split_into_chunks(text, chunk_chars=1000, overlap=100)

        # ì„ë² ë”© ë° ì €ì¥
        for i, chunk in enumerate(chunks):
            chunk_id = f"{file_name}_{i}_{hashlib.md5(chunk.encode()).hexdigest()[:8]}"
            embedding = embedding_model.encode(chunk).tolist()

            metadata = {
                'file_name': file_name,
                'chunk_index': i,
                'owner_id': owner_id,
                'created_at': datetime.now().isoformat()
            }

            collection.add(
                ids=[chunk_id],
                embeddings=[embedding],
                metadatas=[metadata],
                documents=[chunk]
            )

        logger.info(f"RAG ì €ì¥ ì™„ë£Œ: {file_name} ({len(chunks)} ì²­í¬)")
        return True

    except Exception as e:
        logger.error(f"RAG ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

async def rag_query(query: str, owner_id: str = None, top_k: int = 3) -> str:
    """RAG ì¿¼ë¦¬ ìˆ˜í–‰"""
    if not ENABLE_RAG or not vector_store or not embedding_model:
        return "RAG ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤"

    try:
        collection_name = f"docs_{owner_id}" if owner_id else "docs_default"
        collection = vector_store.get_or_create_collection(name=collection_name)

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = embedding_model.encode(query).tolist()

        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        if not results['documents']:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
            context_parts.append(f"ë¬¸ì„œ {i+1} ({metadata['file_name']}):\n{doc}")

        context = "\n\n".join(context_parts)

        # ë‹µë³€ ìƒì„±
        prompt = f"""ë¬¸ì„œ ê·¼ê±° ì¸ìš©(íŒŒì¼ëª…/ìŠ¬ë¼ì´ë“œ/ì‹œíŠ¸/í˜ì´ì§€/ì„¹ì…˜ í—¤ë”©)
ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'ëª¨ë¥´ê² ë‹¤'ë¡œ ì‘ë‹µ
ê°„ê²°í•˜ê²Œ, ëª©ë¡ ìœ„ì£¼

ì§ˆë¬¸: {query}

ì°¸ê³  ë¬¸ì„œ:
{context}

ë‹µë³€:"""

        response = model.generate_content(prompt)
        return response.text.strip()

    except Exception as e:
        logger.error(f"RAG ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
        return f"RAG ì¿¼ë¦¬ ì˜¤ë¥˜: {str(e)}"

# ===== í…”ë ˆê·¸ë¨ ë´‡ ì „ìš© ì‹¤í–‰ í•¨ìˆ˜ =====

async def run_telegram_bot():
    """í…”ë ˆê·¸ë¨ ë´‡ë§Œ ì‹¤í–‰"""
    logger.info("í…”ë ˆê·¸ë¨ ë´‡ ì‹œì‘")

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    if not await init_services():
        logger.error("ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return

    # Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ì„ íƒ)
    if os.path.exists('credentials.json'):
        await init_drive_service()

    # í…”ë ˆê·¸ë¨ ë´‡ ì´ˆê¸°í™”
    if TELEGRAM_BOT_TOKEN:
        telegram_app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

        # í•¸ë“¤ëŸ¬ ë“±ë¡
        telegram_app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
        telegram_app.add_handler(CommandHandler("analyze", handle_analyze))
        telegram_app.add_handler(CommandHandler("summarize", handle_summarize))
        telegram_app.add_handler(CommandHandler("list", handle_list))
        telegram_app.add_handler(CommandHandler("ask", handle_ask))
        telegram_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

        logger.info("í…”ë ˆê·¸ë¨ ë´‡ í•¸ë“¤ëŸ¬ ë“±ë¡ ì™„ë£Œ")

        # ë´‡ ì‹¤í–‰
        await telegram_app.run_polling()
    else:
        logger.warning("TELEGRAM_BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•„ í…”ë ˆê·¸ë¨ ë´‡ì„ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

    logger.info("í…”ë ˆê·¸ë¨ ë´‡ ì¢…ë£Œ")

# ===== ë©”ì¸ í•¨ìˆ˜ =====

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("125 Build Automation Enhanced ì‹œì‘")

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    if not await init_services():
        logger.error("ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return

    # Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ì„ íƒ)
    if os.path.exists('credentials.json'):
        await init_drive_service()

    # í…”ë ˆê·¸ë¨ ë´‡ ì´ˆê¸°í™”
    if TELEGRAM_BOT_TOKEN:
        telegram_app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

        # í•¸ë“¤ëŸ¬ ë“±ë¡
        telegram_app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
        telegram_app.add_handler(CommandHandler("analyze", handle_analyze))
        telegram_app.add_handler(CommandHandler("summarize", handle_summarize))
        telegram_app.add_handler(CommandHandler("list", handle_list))
        telegram_app.add_handler(CommandHandler("ask", handle_ask))
        telegram_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

        logger.info("í…”ë ˆê·¸ë¨ ë´‡ í•¸ë“¤ëŸ¬ ë“±ë¡ ì™„ë£Œ")

        # ë´‡ ì‹¤í–‰
        await telegram_app.run_polling()
    else:
        logger.warning("TELEGRAM_BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•„ í…”ë ˆê·¸ë¨ ë´‡ì„ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

    logger.info("125 Build Automation Enhanced ì¢…ë£Œ")

if __name__ == "__main__":
    print("125 Build Automation Enhanced - Fixed Bot (Final)")
    try:
        # Create a proper event loop with cleanup
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            loop.run_until_complete(run_telegram_bot())
        except KeyboardInterrupt:
            print("\nINFO: Bot stopped by user")
        except Exception as e:
            print(f"CRITICAL ERROR: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # Clean up pending tasks
            pending = asyncio.all_tasks(loop)
            for task in pending:
                task.cancel()
            
            if pending:
                try:
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                except Exception:
                    pass
            
            loop.close()
            
    except Exception as e:
        print(f"FATAL ERROR: {e}")
        sys.exit(1)
